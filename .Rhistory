# Fit 2 models
modelBefore<-lm(Gas~Temp, data=whiteside, subset=(Insul=="Before"))
modelAfter<-lm(Gas~Temp, data=whiteside, subset=(Insul=="After"))
coef(modelBefore)
coef(modelAfter)
print(modelBefore)
anova(modelBefore)
summary(modelAfter)
# Corn data
corn<-read.csv('corn.csv', header=T, sep=",")
# Residuals vs time
corn<-read.table('corn.csv', header=T, sep=",")
model<-lm(YIELD~RAINFALL+I(RAINFALL^2), data=corn)
# Consumer Index data set
install.packages("rlang")
install.packages("rlang")
install.packages("devtools")
install.packages("devtools")
library(devtools)
library(rlang)
install.packages("devtools")
install.packages("devtools")
library(devtools)
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
# Consumer Index data set
remove.packages("rlang")
install.packages("rlang")
install.packages("rlang")
# Consumer Index data set
install.packages("rlang")
library(rlang)
install.packages("devtools")
library(devtools)
install.packages("usethis")
library(devtools)
devtools::install_github("vitara-p/AppRegR", force = T)
library(AppRegR)
data (ConsumerIndex)
head(ConsumerIndex)
library(usdm)
vif(ConsumerIndex[,-6])
OLSConsumer<-lm(housing~., ConsumerIndex)
summary(OLSConsumer)
# Ridge Regression
library(lmridge)
ridgeConsumer<-lmridge(housing~., ConsumerIndex, K=seq(0,3,0.1))
plot(ridgeConsumer)
cv.plot(ridgeConsumer)
ridgeConsumer<-lmridge(housing~., ConsumerIndex, K=0.25)
summary(ridgeConsumer)
# PCA
consumer.pca<-prcomp(ConsumerIndex[,-6], center=TRUE, scale=TRUE)
print(consumer.pca)
plot(consumer.pca, type="l")
summary(consumer.pca)
pc<-predict(consumer.pca , newdata = ConsumerIndex[,-6])
head(pc)
newdf<-data.frame(PC1=pc[,1], PC2=pc[,2], housing=ConsumerIndex[,6])
head(newdf)
modelPC<-lm(housing~., data=newdf)
summary(modelPC)
plot(resid(model))
par(mfrow=c(1,1))
plot(resid(model))
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv('InAppPurchase.csv', header = T, sep = ",")
summary(data)
head(data)
summary(data)
logitplot<-function(y,x,ncat=40,...)
{
brksx<-unique(quantile(x,probs=(0:ncat)/ncat))
nbrksx<-length(brksx)
cutx<-cut(x,breaks=brksx,include.lowest=TRUE)
yt<-table(data.frame(y,cutx))
mx<-tapply(x,cutx,FUN=mean)
logity<-log((yt[2,]+0.5)/(yt[1,]+0.5))
plot(mx,logity,...)
}
par(mfrow=c(4,2))
logitplot(Buy, Age, xlab="Age", ylab="adjusted sample logit")
logitplot(Buy, Age, xlab="Age", ylab="Buy")
attach(data)
logitplot(Buy, Age, xlab="Age", ylab="Buy")
logitplot(Age, Buy, xlab="Age", ylab="Buy")
plot(Age, Buy, xlab="Age", ylab="Buy")
plot(Buy, Age, xlab="Age", ylab="Buy")
boxplot(Buy, Age, xlab="Age", ylab="Buy")
boxplot(Age, Buy, xlab="Age", ylab="Buy")
summary(data)
par(mfrow=c(4,2))
boxplot(Age, Buy)
boxplot(Sex, Buy)
boxplot(Income, Buy)
boxplot(Months, Buy)
boxplot(Hours, Buy)
boxplot(CreditCard, Buy)
boxplot(Facebook, Buy)
par(mfrow=c(3,3))
par(mfrow=c(3,3))
boxplot(Age, Buy)
boxplot(Sex, Buy)
boxplot(Income, Buy)
boxplot(Months, Buy)
boxplot(Hours, Buy)
boxplot(CreditCard, Buy)
boxplot(Facebook, Buy)
fmod <- glm(Buy~., data=data, family=binomial(link="logit"))
summary(fmod)
plot(fmod, 1)
plot(fmod, 2)
plot(fmod, 3)
plot(fmod, 4)
par(mfrow=c(3,1))
par(mfrow=c(3,1))
plot(fmod, 1)
plot(fmod, 2)
plot(fmod, 4)
par(mfrow=c(1,3))
par(mfrow=c(1,3))
plot(fmod, 1)
plot(fmod, 2)
plot(fmod, 4)
par(mfrow=c(1,2))
plot(fmod, 1)
plot(fmod, 2)
library(olsrr)
ols_plot_resid_lev(model)
library(olsrr)
ols_plot_resid_lev(fmod)
library(olsrr)
ols_plot_cooksd_bar(fmod)
plot(fmod,4)
influence.measures(fmod)
plot(fmod,4)
newdata <- data[-c(2,3,14)]
fmod <- glm(Buy~., data=newdata, family=binomial(link="logit"))
summary(fmod)
par(mfrow=c(1,2))
plot(fmod,1)
plot(fmod,2)
mod1 <- step(fmod)
summary(mod1)
mod1 <- step(fmod, direction ="backward", k= log(nrow(newdata)))
summary(mod1)
par(mfrow=c(1,2))
plot(mod1,1)
plot(mod2,2)
plot(mod1,2)
par(mfrow=c(1,2))
plot(mod1,1)
plot(mod1,2)
plot(mod1,4)
influence.measures(mod1)
# Shapiro-Wilk Test
shapiro.test(resid(model))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(model1)
# Shapiro-Wilk Test
shapiro.test(resid(mod1))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(mod1)
shapiro.test(resid(mod1))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(mod1)
# Run Test
# install.packages('randtests')
library(randtests)
runs.test(resid(model))
# Durbin-Watson Test
dwtest(model)
shapiro.test(resid(mod1))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(mod1)
# Run Test
# install.packages('randtests')
library(randtests)
runs.test(resid(mod1))
# Durbin-Watson Test
dwtest(mod1)
hosmerlem <-function (y, yhat, g = 10)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(Buy, mod1$fitted.values)
LRT <- deviance(mod1) - deviance(fmod)
1-pchisq(LRT, df.residual(mod)-df.residual(fmod))
1-pchisq(LRT, df.residual(mod1)-df.residual(fmod))
summary(mod1)
predv <- data.frame(Age = 22, Sex = 0, Income = 20, Months = 6, Hours = 25, CreditCard = 0, Facebook = 1)
plink <- predict(mod1, newdata=predv, se.fit=T, type="link")
predv <- data.frame(Age = 22, Sex = 0, Income = 20, Months = 6, Hours = 25, CreditCard = 0, Facebook = 1)
predict(mod1, newdata=predv, se.fit=T, type="link")
pchisq(deviance(mod1), df.residual(mod1), lower=FALSE)
predict(mod1, newdata=predv, se.fit=T, type="response")
mod1 <- step(fmod, direction = "both", trace = 0)
summary(mod1)
drop1(fmod, test="F")
newdata <- data[-c(2,3,14),]
fmod <- glm(Buy~., data=data, family=binomial(link="logit"))
summary(fmod)
fmod <- glm(Buy~., data=newdata, family=binomial(link="logit"))
summary(fmod)
mod1 <- step(fmod, direction = "both", trace = 0)
summary(mod1)
mod1 <- step(fmod, direction ="backward", k= log(nrow(newdata)))
summary(mod1)
par(mfrow=c(1,2))
plot(mod1,1)
plot(mod1,2)
mod1 <- step(fmod, direction ="backward", k= log(nrow(newdata)))
summary(mod1)
par(mfrow=c(1,2))
plot(mod1,1)
plot(mod1,2)
plot(mod1,4)
newdata <- newdata[-c(4,37,395),]
mod2 <- glm(Buy~Income+Months+CreditCard, data=newdata, family=binomial(link="logit"))
summary(mod2)
# Shapiro-Wilk Test
shapiro.test(resid(mod2))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(mod2)
# Run Test
# install.packages('randtests')
library(randtests)
runs.test(resid(mod2))
# Durbin-Watson Test
dwtest(mod2)
pchisq(deviance(mod2), df.residual(mod2), lower=FALSE)
hosmerlem <-function (y, yhat, g = 10)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(Buy, mod2$fitted.values)
hosmerlem <-function (y, yhat, g = 10)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(Buy, mod2$fitted.values)
hosmerlem <-function (y, yhat, g = 10)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(Buy, mod1$fitted.values)
hosmerlem(Buy, mod2$fitted.values)
hosmerlem <-function (y, yhat, g = 5)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(Buy, mod2$fitted.values)
plot(mod1,4)
#influence.measures(mod1)
# Shapiro-Wilk Test
shapiro.test(resid(mod1))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(mod1)
# Run Test
# install.packages('randtests')
library(randtests)
runs.test(resid(mod1))
# Durbin-Watson Test
dwtest(mod1)
pchisq(deviance(mod1), df.residual(mod1), lower=FALSE)
hosmerlem <-function (y, yhat, g = 10)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(Buy, mod1$fitted.values)
LRT <- deviance(mod1) - deviance(fmod)
1-pchisq(LRT, df.residual(mod1)-df.residual(fmod))
drop1(fmod, test="F")
summary(mod1)
predv <- data.frame(Age = 22, Sex = 0, Income = 20, Months = 6, Hours = 25, CreditCard = 0, Facebook = 1)
predict(mod1, newdata=predv, se.fit=T, type="response")
hosmerlem(newdata$Buy, mod1$fitted.values)
hosmerlem <-function (y, yhat, g = 10)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(newdata$Buy, mod1$fitted.values)
hosmerlem(data$Buy, mod1$fitted.values)
hosmerlem(newdata$Buy, mod1$fitted.values)
newdata <- data[-c(4,37,395),]
mod1 <- glm(Buy~., data=newdata, family=binomial(link="logit"))
summary(mod1)
shapiro.test(resid(mod1))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(mod1)
# Run Test
# install.packages('randtests')
library(randtests)
runs.test(resid(mod1))
# Durbin-Watson Test
dwtest(mod1)
pchisq(deviance(mod1), df.residual(mod1), lower=FALSE)
hosmerlem <-function (y, yhat, g = 10)
{
cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0,1, 1/g)), include.lowest = T)
obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
chisq <- sum((obs - expect)^2/expect)
P <- 1 - pchisq(chisq, g - 2)
c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
}
hosmerlem(newdata$Buy, mod1$fitted.values)
LRT <- deviance(mod1) - deviance(fmod)
1-pchisq(LRT, df.residual(mod1)-df.residual(fmod))
summary(mod1)
mod1 <- glm(Buy~Income+Months+CreditCard, data=newdata, family=binomial(link="logit"))
summary(mod1)
shapiro.test(resid(mod1))
# Breusch-Pagan Test
# install.packages('lmtest')
library(lmtest)
bptest(mod1)
# Run Test
# install.packages('randtests')
library(randtests)
runs.test(resid(mod1))
# Durbin-Watson Test
dwtest(mod1)
pchisq(deviance(mod1), df.residual(mod1), lower=FALSE)
LRT <- deviance(mod1) - deviance(fmod)
1-pchisq(LRT, df.residual(mod1)-df.residual(fmod))
summary(mod1)
predv <- data.frame(Age = 22, Sex = 0, Income = 20, Months = 6, Hours = 25, CreditCard = 0, Facebook = 1)
predict(mod1, newdata=predv, se.fit=T, type="response")
mod1 <- update(mod1, data=newdata)
summary(mod1)
##### Simulate MA(1) #####
ma.sim <- arima.sim(list(order = c(0,0,1), ma = 0.9), n = 100)
##### Time series plot of MA(1) and its sample acf #####
par(mfrow=c(2,1))
plot(ma.sim,ylab=expression(Y[t]),xlab="Time",type="o",main="MA(1) simulation")
acf(ma.sim,main="Sample ACF")
##### Scatter plots (need library(TSA) for zlag function) #####
par(mfrow=c(2,1))
plot(y=ma.sim,x=zlag(ma.sim,1),ylab=expression(Y[t]),xlab=expression(Y[t-1]),type='p',main="Lag 1 scatterplot")
plot(y=ma.sim,x=zlag(ma.sim,2),ylab=expression(Y[t]),xlab=expression(Y[t-2]),type='p',main="Lag 2 scatterplot")
par(mfrow=c(2,1))
plot(y=ma.sim,x=zlag(ma.sim,1),ylab=expression(Y[t]),xlab=expression(Y[t-1]),type='p',main="Lag 1 scatterplot")
##### Simulate MA(1) #####
ma.sim <- arima.sim(list(order = c(0,0,1), ma = 0.9), n = 100)
##### Scatter plots (need library(TSA) for zlag function) #####
par(mfrow=c(2,1))
plot(y=ma.sim,x=zlag(ma.sim,1),ylab=expression(Y[t]),xlab=expression(Y[t-1]),type='p',main="Lag 1 scatterplot")
plot(y=ma.sim,x=zlag(ma.sim,2),ylab=expression(Y[t]),xlab=expression(Y[t-2]),type='p',main="Lag 2 scatterplot")
##### Scatter plots (need library(TSA) for zlag function) #####
library(TSA)
par(mfrow=c(2,1))
##### Scatter plots (need library(TSA) for zlag function) #####
import(TSA)
##### Scatter plots (need library(TSA) for zlag function) #####
imports(TSA)
##### Scatter plots (need library(TSA) for zlag function) #####
install.packages(TSA)
library(TSA)
install.packages("TSA")
##### Scatter plots (need library(TSA) for zlag function) #####
#install.packages("TSA")
library(TSA)
par(mfrow=c(2,1))
plot(y=ma.sim,x=zlag(ma.sim,1),ylab=expression(Y[t]),xlab=expression(Y[t-1]),type='p',main="Lag 1 scatterplot")
plot(y=ma.sim,x=zlag(ma.sim,2),ylab=expression(Y[t]),xlab=expression(Y[t-2]),type='p',main="Lag 2 scatterplot")
##### Simulate MA(1) #####
ma.sim <- arima.sim(list(order = c(0,0,1), ma = -0.9), n = 100)
##### Time series plot of MA(1) and its sample acf #####
par(mfrow=c(2,1))
plot(ma.sim,ylab=expression(Y[t]),xlab="Time",type="o",main="MA(1) simulation")
acf(ma.sim,main="Sample ACF")
##### Scatter plots (need library(TSA) for zlag function) #####
par(mfrow=c(2,1))
plot(y=ma.sim,x=zlag(ma.sim,1),ylab=expression(Y[t]),xlab=expression(Y[t-1]),type='p',main="Lag 1 scatterplot")
plot(y=ma.sim,x=zlag(ma.sim,2),ylab=expression(Y[t]),xlab=expression(Y[t-2]),type='p',main="Lag 2 scatterplot")
##### Simulate MA(2) #####
ma.sim <- arima.sim(list(order = c(0,0,2), ma = c(-0.9,0.7)), n = 100)
##### Time series plot of MA(2) and its sample acf #####
par(mfrow=c(2,2))
plot(ma.sim,ylab=expression(Y[t]),xlab="Time",type="o",main="MA(2) simulation")
acf(ma.sim,main="Sample ACF")
##### Scatter plots (need library(TSA) for zlag function) #####
plot(y=ma.sim,x=zlag(ma.sim,1),ylab=expression(Y[t]),xlab=expression(Y[t-1]),type='p',main="Lag 1 scatterplot")
plot(y=ma.sim,x=zlag(ma.sim,2),ylab=expression(Y[t]),xlab=expression(Y[t-2]),type='p',main="Lag 2 scatterplot")
par(mfrow=c(2,1))
### Calculate theoretical ACF ###
acf <- ARMAacf(ar = c(0.9), lag.max = 20)
### Plot ACF ####
plot(acf, x = 0:20, type = "h", ylim = c(-1,1), xlab = "h", ylab = "Autocorrelation", main = "Population ACF")
par(mfrow=c(1,1))
plot(acf, x = 0:20, type = "h", ylim = c(-1,1), xlab = "h", ylab = "Autocorrelation", main = "Population ACF")
abline(h = 0)
##### Simulate AR(1) #####
ar.sim <- arima.sim(list(order = c(1,0,0), ar = 0.9), n = 100)
### Plot ACF ####
acf(ar.sim,main="Sample ACF")
library(installr)
updateR()
setwd("~/Master/Time Serie Analysis/Case 2")
library(forecast)
library(TSA)
## Try hourly incoming wires ##
data <- read.csv("amarcord_1hr.csv")
hourly <- ts(data$Trans_Amt, frequency = 7)
plot(hourly)
model.ets = ets(hourly)
par(mfrow=c(1,1))
plot(forecast(model.ets, h = 49))
summary(model.ets)
plot(forecast(model.ets, h=49)$fitted)
fit <- forecast(model.ets, h=49)$fitted
plot(hourly)
lines(fit, col='red')
accuracy(hourly, fit)
data <- read.csv("amarcord_1hr.csv")
hourly <- ts(data$Trans_Amt, frequency = 7)
model.test <- auto.arima(hourly, stepwise = T, approximation = F, trace = T)
summary(model.test)
list.model <- list(model1,model2,model3,model4)
model1 <- Arima(hourly,order=c(0,0,0),seasonal=c(2,0,0),method='ML')
model2 <- Arima(hourly,order=c(1,0,0),seasonal=c(2,0,0),method='ML')
model3 <- Arima(hourly,order=c(0,0,1),seasonal=c(2,0,0),method='ML')
model4 <- Arima(hourly,order=c(1,0,1),seasonal=c(2,0,0),method='ML')
list.model <- list(model1,model2,model3,model4)
for (i in list.model){
print(summary(i))
}
for (i in list.model){
fit <- forecast(i)$fitted
par(mfrow=c(1,1))
plot(hourly)
lines(fit, col='red')
}
upper <- fitted(model.ets) + 1.96*(model.ets$sigma)
lower <- fitted(model.ets) - 1.96*(model.ets$sigma)
plot(hourly, type="n")
polygon(c(time(hourly),rev(time(hourly))), c(upper,rev(lower)),
col=rgb(0,0,0.6,0.2), border=FALSE)
lines(hourly)
lines(fitted(model.ets),col='red')
out <- (hourly < lower | hourly > upper)
points(time(hourly)[out], hourly[out], pch=19, col='blue')
upper <- fitted(model4) + 1.96*sqrt(model4$sigma2)
lower <- fitted(model4) - 1.96*sqrt(model4$sigma2)
plot(hourly, type="n", ylim=range(lower,upper))
polygon(c(time(hourly),rev(time(hourly))), c(upper,rev(lower)),
col=rgb(0,0,0.6,0.2), border=FALSE)
lines(hourly)
lines(fitted(model4),col='red')
out <- (hourly < lower | hourly > upper)
points(time(hourly)[out], hourly[out], pch=19, col='blue')
data <- read.csv("amarcord_1hr.csv")
hourly <- ts(data$Trans_Amt, frequency = 7)
plot(hourly)
for (i in list.model){
par(mfrow=c(1,2))
hist(rstandard(i),xlab="Standardised residuals",main="")
qqnorm(rstandard(i))
qqline(rstandard(i))
}
tsdiag(model4,gof.lag=20)
